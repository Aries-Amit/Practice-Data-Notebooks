{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c3acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text/ paragraph for the processing\n",
    "var = \"Autobiography thus takes stock of the autobiographer's life from the moment of composition. While biographers generally rely on a wide variety of documents and viewpoints, autobiography may be based entirely on the writer's memory. The memoir form is closely associated with autobiography but it tends, as Pascal claims, to focus less on the self and more on others during the autobiographer's review of their own life.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcfaae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk\n",
    "import nltk\n",
    "\n",
    "\n",
    "# downloading missing file 'punkt'\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e31b8663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amit9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading missing file 'stopwords'\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0677ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\amit9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading missing file 'averaged_perceptron_tagger'\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c71631f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amit9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading missing file 'wordnet'\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b576d8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Autobiography',\n",
       " 'thus',\n",
       " 'takes',\n",
       " 'stock',\n",
       " 'of',\n",
       " 'the',\n",
       " 'autobiographer',\n",
       " \"'s\",\n",
       " 'life',\n",
       " 'from',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'of',\n",
       " 'composition',\n",
       " '.',\n",
       " 'While',\n",
       " 'biographers',\n",
       " 'generally',\n",
       " 'rely',\n",
       " 'on',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'documents',\n",
       " 'and',\n",
       " 'viewpoints',\n",
       " ',',\n",
       " 'autobiography',\n",
       " 'may',\n",
       " 'be',\n",
       " 'based',\n",
       " 'entirely',\n",
       " 'on',\n",
       " 'the',\n",
       " 'writer',\n",
       " \"'s\",\n",
       " 'memory',\n",
       " '.',\n",
       " 'The',\n",
       " 'memoir',\n",
       " 'form',\n",
       " 'is',\n",
       " 'closely',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'autobiography',\n",
       " 'but',\n",
       " 'it',\n",
       " 'tends',\n",
       " ',',\n",
       " 'as',\n",
       " 'Pascal',\n",
       " 'claims',\n",
       " ',',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'less',\n",
       " 'on',\n",
       " 'the',\n",
       " 'self',\n",
       " 'and',\n",
       " 'more',\n",
       " 'on',\n",
       " 'others',\n",
       " 'during',\n",
       " 'the',\n",
       " 'autobiographer',\n",
       " \"'s\",\n",
       " 'review',\n",
       " 'of',\n",
       " 'their',\n",
       " 'own',\n",
       " 'life',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_tokenize - to create tokens(each word in sentence is refered as token) of the data.\n",
    "tokens = nltk.word_tokenize(var)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb51630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Autobiography thus takes stock of the autobiographer's life from the moment of composition.\",\n",
       " \"While biographers generally rely on a wide variety of documents and viewpoints, autobiography may be based entirely on the writer's memory.\",\n",
       " \"The memoir form is closely associated with autobiography but it tends, as Pascal claims, to focus less on the self and more on others during the autobiographer's review of their own life.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent_tokenize - to create sentence tokens from the data. \n",
    "sent = nltk.sent_tokenize(var)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b75db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autobiography thus takes stock of the autobiographer s life from the moment of composition  While biographers generally rely on a wide variety of documents and viewpoints  autobiography may be based entirely on the writer s memory  The memoir form is closely associated with autobiography but it tends  as Pascal claims  to focus less on the self and more on others during the autobiographer s review of their own life '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step - 1:\n",
    "\n",
    "# importing regular expressions package\n",
    "import re\n",
    "\n",
    "# sub() - used to remove the punctuations\n",
    "# take 3 arguments - regular expression, replacement, variable in which we have to perform operation\n",
    "processed_var = re.sub(\"[^a-zA-Z]\", ' ', var)\n",
    "\n",
    "processed_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d12df34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobiography thus takes stock of the autobiographer s life from the moment of composition  while biographers generally rely on a wide variety of documents and viewpoints  autobiography may be based entirely on the writer s memory  the memoir form is closely associated with autobiography but it tends  as pascal claims  to focus less on the self and more on others during the autobiographer s review of their own life '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: \n",
    "\n",
    "# lower() - to convert all characters in small letters/ lowercase.\n",
    "processed_var = processed_var.lower()\n",
    "processed_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43084461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 3:\n",
    "\n",
    "# import stopwords lists\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# creating a set of stopwords of language 'english' to remove repeatation of the words... \n",
    "stop_words = set(stopwords.words('english'))\n",
    "# removing the word 'not' from stopword list\n",
    "stop_words.remove('not')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "662d1e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Autobiography', 'NNP'),\n",
       " ('thus', 'RB'),\n",
       " ('takes', 'VBZ'),\n",
       " ('stock', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('autobiographer', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('life', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('moment', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('composition', 'NN'),\n",
       " ('.', '.'),\n",
       " ('While', 'IN'),\n",
       " ('biographers', 'NNS'),\n",
       " ('generally', 'RB'),\n",
       " ('rely', 'VBP'),\n",
       " ('on', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('wide', 'JJ'),\n",
       " ('variety', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('documents', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('viewpoints', 'NNS'),\n",
       " (',', ','),\n",
       " ('autobiography', 'NN'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('based', 'VBN'),\n",
       " ('entirely', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('writer', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('memory', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('memoir', 'JJ'),\n",
       " ('form', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('closely', 'RB'),\n",
       " ('associated', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('autobiography', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('tends', 'VBZ'),\n",
       " (',', ','),\n",
       " ('as', 'IN'),\n",
       " ('Pascal', 'NNP'),\n",
       " ('claims', 'NNS'),\n",
       " (',', ','),\n",
       " ('to', 'TO'),\n",
       " ('focus', 'VB'),\n",
       " ('less', 'RBR'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('self', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('more', 'JJR'),\n",
       " ('on', 'IN'),\n",
       " ('others', 'NNS'),\n",
       " ('during', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('autobiographer', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('review', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing pos tags for all the tokens...\n",
    "tags = nltk.pos_tag(tokens)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1024ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4:\n",
    "\n",
    "# importing stemmer and lemmatizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9954b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating object of the Porter Stemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7993bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating object for the Lemmatizer\n",
    "wn = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e102082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autobiography',\n",
       " 'thus',\n",
       " 'takes',\n",
       " 'stock',\n",
       " 'of',\n",
       " 'the',\n",
       " 'autobiographer',\n",
       " 's',\n",
       " 'life',\n",
       " 'from',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'of',\n",
       " 'composition',\n",
       " 'while',\n",
       " 'biographers',\n",
       " 'generally',\n",
       " 'rely',\n",
       " 'on',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'documents',\n",
       " 'and',\n",
       " 'viewpoints',\n",
       " 'autobiography',\n",
       " 'may',\n",
       " 'be',\n",
       " 'based',\n",
       " 'entirely',\n",
       " 'on',\n",
       " 'the',\n",
       " 'writer',\n",
       " 's',\n",
       " 'memory',\n",
       " 'the',\n",
       " 'memoir',\n",
       " 'form',\n",
       " 'is',\n",
       " 'closely',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'autobiography',\n",
       " 'but',\n",
       " 'it',\n",
       " 'tends',\n",
       " 'as',\n",
       " 'pascal',\n",
       " 'claims',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'less',\n",
       " 'on',\n",
       " 'the',\n",
       " 'self',\n",
       " 'and',\n",
       " 'more',\n",
       " 'on',\n",
       " 'others',\n",
       " 'during',\n",
       " 'the',\n",
       " 'autobiographer',\n",
       " 's',\n",
       " 'review',\n",
       " 'of',\n",
       " 'their',\n",
       " 'own',\n",
       " 'life']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tokens using split function (can be done using word_tokenize function too.)\n",
    "tok = processed_var.split()\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b79310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobiographi thu take stock autobiograph life moment composit biograph gener reli wide varieti document viewpoint autobiographi may base entir writer memori memoir form close associ autobiographi tend pascal claim focu less self other autobiograph review life'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4:\n",
    "\n",
    "# Stemmer does not have the knowledge of the language english\n",
    "# using list comprehension to remove stopwords and perform the stemming operation on the text\n",
    "corpus = [ps.stem(word) for word in tok if word not in stop_words]\n",
    "\" \".join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2981a15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autobiographi',\n",
       " 'thu',\n",
       " 'take',\n",
       " 'stock',\n",
       " 'autobiograph',\n",
       " 'life',\n",
       " 'moment',\n",
       " 'composit',\n",
       " 'biograph',\n",
       " 'gener',\n",
       " 'reli',\n",
       " 'wide',\n",
       " 'varieti',\n",
       " 'document',\n",
       " 'viewpoint',\n",
       " 'autobiographi',\n",
       " 'may',\n",
       " 'base',\n",
       " 'entir',\n",
       " 'writer',\n",
       " 'memori',\n",
       " 'memoir',\n",
       " 'form',\n",
       " 'close',\n",
       " 'associ',\n",
       " 'autobiographi',\n",
       " 'tend',\n",
       " 'pascal',\n",
       " 'claim',\n",
       " 'focu',\n",
       " 'less',\n",
       " 'self',\n",
       " 'other',\n",
       " 'autobiograph',\n",
       " 'review',\n",
       " 'life']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d1fc1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobiography thus take stock autobiographer life moment composition biographer generally rely wide variety document viewpoint autobiography may based entirely writer memory memoir form closely associated autobiography tends pascal claim focus le self others autobiographer review life'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizer has database having the rules and knowledge of English words and writing Sentences.\n",
    "# using list comprehension to remove stopwords and perform Lemmatize operation on the text...\n",
    "corpus2 = [wn.lemmatize(word) for word in tok if word not in stop_words]\n",
    "\n",
    "# joining the tokens back to form a sentence/ paragraph.\n",
    "corpus3 = \" \".join(corpus2)\n",
    "corpus3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3a0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5:\n",
    "\n",
    "# Importing packages to transform the text into numerical data\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce37a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object for CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2033461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object for TfidfVectorizer\n",
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8dace19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing the transformation, it will result an object matrix(generator object)\n",
    "arr = cv.fit_transform(corpus2)\n",
    "\n",
    "# Converting the matrix to array\n",
    "arr = arr.toarray()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "814b6d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['associated', 'autobiographer', 'autobiography', 'based',\n",
       "       'biographer', 'claim', 'closely', 'composition', 'document',\n",
       "       'entirely', 'focus', 'form', 'generally', 'le', 'life', 'may',\n",
       "       'memoir', 'memory', 'moment', 'others', 'pascal', 'rely', 'review',\n",
       "       'self', 'stock', 'take', 'tends', 'thus', 'variety', 'viewpoint',\n",
       "       'wide', 'writer'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the names of the columns / features\n",
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec965d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d09fd89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de4a8c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10e60ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36x32 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 36 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing the transformation, it will result an object matrix(generator object)\n",
    "arr2 = tf.fit_transform(corpus2)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de52a8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the matrix to array\n",
    "arr2 = arr2.toarray()\n",
    "arr2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
